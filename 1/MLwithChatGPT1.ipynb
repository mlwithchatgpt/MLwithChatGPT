{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# FeedForward Neural Network\n",
        "\n",
        "\\begin{align*}\n",
        "\\text{Input Layer} \\quad (l &= 1): \\\\\n",
        "a^{(1)} &= x \\\\\n",
        "\\\\\n",
        "\\text{Hidden Layers} \\quad (l &= 2, 3, \\ldots, L-1): \\\\\n",
        "z^{(l)} &= W^{(l)} a^{(l-1)} + b^{(l)} \\\\\n",
        "a^{(l)} &= f^{(l)}(z^{(l)}) \\\\\n",
        "\\\\\n",
        "\\text{Output Layer} \\quad (l &= L): \\\\\n",
        "z^{(L)} &= W^{(L)} a^{(L-1)} + b^{(L)} \\\\\n",
        "\\hat{y} &= a^{(L)} = f^{(L)}(z^{(L)})\n",
        "\\end{align*}\n"
      ],
      "metadata": {
        "id": "9c55vuml-Py0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the architecture of the one-layer feedforward neural network\n",
        "class OneLayerNN(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(OneLayerNN, self).__init__()\n",
        "        self.fc = nn.Linear(input_size, output_size)  # Fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Define input and output sizes\n",
        "    input_size = 10\n",
        "    output_size = 20\n",
        "\n",
        "    # Create an instance of the one-layer feedforward neural network\n",
        "    model = OneLayerNN(input_size, output_size)\n",
        "\n",
        "    # Define some input data (batch size of 1 for simplicity)\n",
        "    input_data = torch.randn(1, input_size)\n",
        "\n",
        "    # Perform forward pass\n",
        "    output = model(input_data)\n",
        "\n",
        "    print(\"Output:\", output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmdcTGMe-TSN",
        "outputId": "30312e5d-1031-4a07-cb87-4f9515a5a5c4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: tensor([[ 0.4594,  0.2626,  0.0250,  0.3324,  0.1247, -0.0387,  0.0589,  0.6150,\n",
            "          0.1814,  0.2420,  0.0439, -0.1569, -0.5358,  0.4796,  0.8291,  0.1185,\n",
            "          0.4857,  0.4156,  0.1636, -1.2368]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(\"Total number of parameters:\", total_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqK9oF5R-cpD",
        "outputId": "7e75e1b6-d47b-4c6a-eb1d-d6ab1cd176b9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 784  # 28x28 = 784, flattened input image\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "# One-layer neural network model\n",
        "class OneLayerNN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(OneLayerNN, self).__init__()\n",
        "        self.fc = nn.Linear(input_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten the input image\n",
        "        out = self.fc(x)\n",
        "        return out\n",
        "\n",
        "# Initialize the model\n",
        "model = OneLayerNN(input_size, num_classes).to(device)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH5V4kcl-2N6",
        "outputId": "829c5a41-2eb5-4e28-f335-ee895ed8bdcd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 307446710.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 14799718.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 138695078.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 14802275.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "num_samples = 5\n",
        "random_indices = np.random.randint(len(train_dataset), size=num_samples)\n",
        "\n",
        "# Plot the samples\n",
        "fig, axes = plt.subplots(1, num_samples, figsize=(10, 2))\n",
        "\n",
        "for i, idx in enumerate(random_indices):\n",
        "    image, label = train_dataset[idx]\n",
        "    axes[i].imshow(image.squeeze().numpy(), cmap='gray')\n",
        "    axes[i].set_title('Label: {}'.format(label))\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "YzojTV-x_C7L",
        "outputId": "b8b90920-46fa-4928-d341-08bf70370ee9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Im6xeXj-9Ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1g0zFrA7-7e5",
        "outputId": "1fc8cacc-e30b-4308-a5a6-f97fdb5c2c9f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 0.8371\n",
            "Epoch [1/5], Step [200/600], Loss: 0.5290\n",
            "Epoch [1/5], Step [300/600], Loss: 0.4045\n",
            "Epoch [1/5], Step [400/600], Loss: 0.4514\n",
            "Epoch [1/5], Step [500/600], Loss: 0.3495\n",
            "Epoch [1/5], Step [600/600], Loss: 0.3676\n",
            "Epoch [2/5], Step [100/600], Loss: 0.3005\n",
            "Epoch [2/5], Step [200/600], Loss: 0.3931\n",
            "Epoch [2/5], Step [300/600], Loss: 0.3801\n",
            "Epoch [2/5], Step [400/600], Loss: 0.4323\n",
            "Epoch [2/5], Step [500/600], Loss: 0.3945\n",
            "Epoch [2/5], Step [600/600], Loss: 0.2730\n",
            "Epoch [3/5], Step [100/600], Loss: 0.3263\n",
            "Epoch [3/5], Step [200/600], Loss: 0.2318\n",
            "Epoch [3/5], Step [300/600], Loss: 0.3532\n",
            "Epoch [3/5], Step [400/600], Loss: 0.2233\n",
            "Epoch [3/5], Step [500/600], Loss: 0.2533\n",
            "Epoch [3/5], Step [600/600], Loss: 0.3785\n",
            "Epoch [4/5], Step [100/600], Loss: 0.3025\n",
            "Epoch [4/5], Step [200/600], Loss: 0.2187\n",
            "Epoch [4/5], Step [300/600], Loss: 0.3271\n",
            "Epoch [4/5], Step [400/600], Loss: 0.2596\n",
            "Epoch [4/5], Step [500/600], Loss: 0.2212\n",
            "Epoch [4/5], Step [600/600], Loss: 0.2982\n",
            "Epoch [5/5], Step [100/600], Loss: 0.2181\n",
            "Epoch [5/5], Step [200/600], Loss: 0.2402\n",
            "Epoch [5/5], Step [300/600], Loss: 0.3464\n",
            "Epoch [5/5], Step [400/600], Loss: 0.2345\n",
            "Epoch [5/5], Step [500/600], Loss: 0.2151\n",
            "Epoch [5/5], Step [600/600], Loss: 0.3346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rarDNw9SAK34",
        "outputId": "a33f2626-00cb-4333-c45a-5526b627807b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4594,  0.2626,  0.0250,  0.3324,  0.1247, -0.0387,  0.0589,  0.6150,\n",
              "          0.1814,  0.2420,  0.0439, -0.1569, -0.5358,  0.4796,  0.8291,  0.1185,\n",
              "          0.4857,  0.4156,  0.1636, -1.2368]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl_E1pRn_-Uw",
        "outputId": "5d9605a3-1d41-43c3-fd63-dadb57c707c9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 92.35 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk8Vz6E4APyX",
        "outputId": "46e2351c-3656-4ba9-9c45-9da923b08c71"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-4.1420e+00, -1.0726e+00,  2.0343e-01, -2.2424e-01, -2.9357e+00,\n",
              "          4.8445e-01, -2.9541e+00, -7.5672e+00,  3.7115e+00, -3.4504e+00],\n",
              "        [-4.4399e+00, -9.4450e+00, -4.2426e+00, -2.4435e+00,  3.9758e+00,\n",
              "          3.5740e-01, -4.3308e+00, -2.6024e+00,  1.7499e+00,  3.2436e+00],\n",
              "        [ 4.6233e+00, -1.1204e+01, -3.2722e+00, -5.0656e+00, -5.6929e+00,\n",
              "          1.5012e+00, -6.4350e+00, -3.4285e+00, -5.5311e+00, -4.8089e+00],\n",
              "        [-7.5313e+00,  4.6000e+00,  9.1538e-01, -8.3588e-01, -1.2953e+00,\n",
              "         -4.0069e+00, -4.5873e+00, -2.1507e+00,  1.6598e+00, -2.8698e+00],\n",
              "        [-6.9642e-01, -7.7546e+00,  1.0916e+00, -1.8605e+00, -2.8230e+00,\n",
              "         -1.7123e+00, -4.7528e+00, -4.2227e+00, -3.1343e+00, -4.8657e+00],\n",
              "        [-3.8351e+00, -5.8601e+00, -4.1559e-01, -5.9654e-01, -3.3273e+00,\n",
              "         -7.2883e+00, -5.5535e+00,  2.1983e+00,  1.4121e+00,  3.4437e+00],\n",
              "        [-2.1848e+00, -4.7032e+00, -5.7563e-01, -6.0751e+00,  4.3164e+00,\n",
              "         -3.1447e+00,  2.0914e+00, -4.7985e+00,  6.5379e-01, -2.6227e+00],\n",
              "        [ 3.0133e-01, -4.5980e+00, -1.4903e+00, -2.6153e+00, -3.6074e+00,\n",
              "          4.3910e+00, -2.6208e+00, -5.5208e+00,  1.1438e+00, -6.6177e+00],\n",
              "        [-4.5863e-01, -6.5351e+00, -1.3894e+00, -6.0181e+00, -1.3362e+00,\n",
              "          3.4839e-01,  7.4876e+00, -6.6710e+00, -3.6146e+00, -5.7543e+00],\n",
              "        [-2.4587e+00, -1.1909e+01, -6.8252e+00, -2.4424e+00, -2.5435e+00,\n",
              "          9.7235e-02, -8.7760e+00,  7.8123e+00, -2.2241e-01,  4.4262e+00],\n",
              "        [-5.3761e+00, -2.5761e+00, -6.4585e+00, -1.2278e+00, -6.0097e+00,\n",
              "          1.3477e+00, -8.2647e+00, -5.8701e+00,  2.9224e+00, -4.9285e+00],\n",
              "        [ 6.9951e+00, -1.5194e+01, -3.5936e+00, -4.2360e+00, -7.7412e+00,\n",
              "          2.8972e+00, -7.0477e+00, -4.6376e+00, -5.5200e+00, -6.5320e+00],\n",
              "        [-4.7610e+00,  5.1151e+00,  4.7131e-01,  7.8930e-02, -5.0349e+00,\n",
              "         -2.7350e+00, -5.7876e+00, -7.1949e+00,  1.6763e+00, -4.8941e+00],\n",
              "        [-2.7913e+00, -8.5709e+00,  4.8775e+00, -2.8464e+00, -5.7853e+00,\n",
              "         -2.4222e+00, -5.1511e+00, -8.5618e+00,  3.1095e+00, -2.2652e+00],\n",
              "        [-3.0157e+00, -3.7942e+00, -2.3522e-01,  4.7133e+00, -4.8406e+00,\n",
              "         -1.8269e+00, -1.0564e+01, -1.3676e+00,  2.0126e+00,  1.5765e+00],\n",
              "        [-4.8565e+00, -3.7311e+00, -3.3356e+00, -6.2369e+00,  6.2796e+00,\n",
              "         -3.3553e+00,  1.0023e+00, -5.8647e+00, -1.4701e+00, -3.7243e+00],\n",
              "        [-2.5785e-01, -1.4965e+01, -8.7816e+00, -4.6298e+00, -1.8011e+00,\n",
              "          1.0608e+00, -5.5100e+00,  5.9294e+00,  6.8539e-01,  5.2950e+00],\n",
              "        [-4.5235e+00, -9.2162e+00, -2.2062e+00, -5.3590e+00, -3.8912e+00,\n",
              "          2.3159e+00, -5.0175e+00, -1.0481e+01,  6.5073e+00, -4.7536e+00],\n",
              "        [-1.7422e+00, -1.3359e+01, -4.0087e+00, -5.4016e+00,  1.4069e+00,\n",
              "         -2.2638e+00, -3.5721e+00,  7.1822e-01,  1.0921e+00,  3.5744e+00],\n",
              "        [-4.1288e+00, -8.8576e+00, -8.9682e+00, -2.4688e+00, -9.0645e-01,\n",
              "         -1.1674e+00, -8.4666e+00,  8.0193e+00, -2.4830e+00,  6.0001e+00],\n",
              "        [-3.1119e+00, -3.4449e+00, -1.4327e+00, -3.1546e-01, -5.4478e+00,\n",
              "          7.8517e-01, -7.6890e+00, -5.3411e+00,  5.1098e+00, -8.1375e-01],\n",
              "        [-3.2480e+00, -9.7954e+00,  1.4319e+00, -4.1058e+00, -3.9365e+00,\n",
              "         -1.1191e+00,  2.2527e+00, -8.8093e+00, -3.2563e+00, -4.3829e+00],\n",
              "        [-5.4623e+00, -1.0184e+00, -3.9056e+00, -1.6934e+00,  2.4714e+00,\n",
              "         -6.6724e-01, -3.1795e+00, -1.6598e+00,  1.4186e-01, -1.1000e+00],\n",
              "        [-6.6210e+00,  6.8075e+00,  1.7327e+00, -1.4287e+00, -3.3454e+00,\n",
              "         -3.8845e+00, -2.9104e+00, -2.9638e+00,  1.2282e+00, -4.0675e+00],\n",
              "        [-1.2971e+00, -1.4182e+01, -8.9255e+00, -7.5915e+00,  1.2587e+00,\n",
              "         -2.0897e+00, -6.0589e+00,  7.9953e-01, -2.6129e+00,  3.9090e+00],\n",
              "        [-2.5803e+00, -3.6680e+00,  2.2344e+00,  1.0996e+00, -5.4758e+00,\n",
              "         -1.9032e+00, -7.0435e+00, -2.6560e+00,  1.2907e+00, -1.7132e+00],\n",
              "        [-7.9690e+00, -1.1491e+00, -1.2882e+00, -2.6896e+00, -4.0704e+00,\n",
              "         -6.1901e-01, -4.2157e+00, -6.2216e+00,  1.9208e+00, -5.0663e+00],\n",
              "        [-2.6582e+00, -7.5577e+00, -2.7132e+00, -8.3334e+00,  5.7420e+00,\n",
              "         -5.8373e+00,  6.1365e-01,  1.4405e+00, -2.4010e+00,  8.2609e-01],\n",
              "        [-1.7660e+00, -8.4910e+00, -2.7613e+00, -7.6823e+00,  5.6166e+00,\n",
              "         -3.4992e+00, -1.2553e+00, -7.2407e-01, -1.2433e+00,  1.2369e+00],\n",
              "        [-3.3591e+00, -1.1445e+01, -6.9097e+00, -1.5354e+00, -3.8307e+00,\n",
              "         -3.6322e-01, -8.9788e+00,  7.8346e+00,  7.6803e-02,  5.7209e+00],\n",
              "        [ 7.8048e+00, -1.1364e+01, -2.5790e+00, -3.8868e-01, -8.2218e+00,\n",
              "          3.0339e+00, -2.0616e+00, -7.1501e+00,  9.9517e-01, -3.8479e+00],\n",
              "        [-6.0820e+00,  5.7513e+00,  7.8136e-01,  6.6703e-01, -5.2184e+00,\n",
              "         -2.9257e+00, -4.2265e+00, -8.6809e-01,  3.8554e-01, -1.7876e+00],\n",
              "        [-1.9106e+00, -1.1914e+01, -1.7649e+00, -5.4108e+00, -1.7401e-01,\n",
              "         -5.4381e+00, -4.6847e+00,  2.0214e+00,  6.3248e-01,  4.4811e+00],\n",
              "        [-3.6901e+00, -1.1066e+01,  6.2868e+00, -4.5362e-01, -5.4020e+00,\n",
              "         -5.2879e-01, -6.8918e+00, -1.1046e+01, -3.0536e+00, -3.9987e+00],\n",
              "        [-4.5470e+00, -4.4349e-01, -4.3455e-01,  1.9573e+00, -5.3951e+00,\n",
              "          6.3200e-01, -6.3503e+00, -6.2785e+00,  4.5734e+00, -2.9942e+00],\n",
              "        [-2.7273e+00, -6.5112e+00, -4.0214e+00, -1.1944e-01, -2.8086e+00,\n",
              "         -1.6326e+00, -7.9914e+00,  7.5179e+00, -1.7220e+00,  4.3342e+00],\n",
              "        [-4.2638e+00, -4.9812e+00, -4.2486e+00,  1.7117e+00, -5.2022e+00,\n",
              "          2.2277e+00, -9.7401e+00, -3.4641e+00,  3.7334e+00, -3.6344e-01],\n",
              "        [-3.1194e+00, -1.1219e+01,  3.7845e+00,  1.6122e+00, -3.9626e+00,\n",
              "         -2.5635e-01, -4.5209e+00, -1.1499e+01, -5.0965e+00, -6.4687e+00],\n",
              "        [ 4.1638e-01, -6.6874e+00, -1.0333e+00, -3.6788e+00, -3.1310e+00,\n",
              "          1.3186e+00,  6.7219e+00, -6.9051e+00, -3.7592e+00, -6.5211e+00],\n",
              "        [ 8.6761e+00, -1.6733e+01, -4.7373e+00, -5.1700e+00, -8.5308e+00,\n",
              "          3.7310e+00, -3.5454e+00, -5.3529e+00, -4.3544e+00, -6.5440e+00],\n",
              "        [ 1.5788e+00, -1.1855e+01, -1.2595e+00, -3.0331e+00, -1.5108e+00,\n",
              "         -1.3524e+00,  1.2796e+00, -5.0316e+00, -2.9338e+00, -2.5895e+00],\n",
              "        [-2.5598e+00, -5.5794e+00, -2.7441e-01,  8.6952e-01, -8.6412e+00,\n",
              "          4.2953e-02,  1.3289e+00, -5.8714e+00, -9.1386e-01, -7.0884e+00],\n",
              "        [-4.1150e+00, -4.0993e+00, -3.3981e+00,  6.4817e+00, -7.8423e+00,\n",
              "          2.8579e+00, -1.5163e+01, -6.5809e+00,  1.2725e+00, -3.8029e+00],\n",
              "        [-2.6401e+00, -5.4676e+00, -1.0689e+00,  1.6743e+00, -5.2571e+00,\n",
              "          2.5590e+00, -9.4864e+00, -3.3746e+00,  3.1063e+00, -6.4497e-01],\n",
              "        [-6.5616e+00, -6.1301e+00, -8.5601e+00, -2.9740e-01, -2.3404e+00,\n",
              "         -7.5178e-01, -8.9077e+00, -1.0705e+00,  1.4397e+00,  2.2299e+00],\n",
              "        [-4.5090e+00, -7.8894e+00, -8.7407e+00, -4.2135e+00,  3.6339e+00,\n",
              "         -2.2276e+00, -6.1568e+00,  3.1709e-01,  1.4438e-01,  4.7143e+00],\n",
              "        [-5.4224e+00,  5.5065e+00,  8.5811e-01,  1.1436e+00, -5.8398e+00,\n",
              "         -2.7526e+00, -5.1123e+00, -1.7885e+00,  5.2600e-01, -2.0048e+00],\n",
              "        [ 1.1094e-01, -1.2913e+01, -4.4271e+00, -6.9111e+00,  4.7292e+00,\n",
              "         -1.6436e+00,  1.6482e+00, -2.0959e+00, -4.6062e+00, -3.4932e+00],\n",
              "        [ 6.3053e+00, -1.1555e+01, -3.9105e+00, -3.2647e+00, -1.2320e+01,\n",
              "          3.5351e+00, -1.0041e+01, -5.7635e+00, -1.8387e+00, -9.9432e+00],\n",
              "        [-8.4478e-01, -1.0531e+01, -1.3604e+00, -6.8307e+00, -2.4967e+00,\n",
              "         -4.6003e+00,  4.9980e+00, -5.7022e+00, -4.3610e+00, -3.1935e+00],\n",
              "        [-4.9539e+00,  5.4399e+00,  8.3536e-01,  1.4603e-01, -3.9184e+00,\n",
              "         -2.4422e+00, -4.2834e+00, -2.1455e+00,  9.0929e-01, -2.6125e+00],\n",
              "        [ 4.8498e+00, -1.0765e+01, -4.0241e+00, -6.9026e-01, -4.4575e+00,\n",
              "          1.1409e+00, -9.2419e+00, -1.1626e+00, -3.5720e+00, -2.5176e+00],\n",
              "        [ 1.0676e+01, -1.8988e+01, -5.1278e+00, -4.9479e+00, -1.0449e+01,\n",
              "          4.6046e+00, -4.1371e+00, -1.0951e+01, -1.5813e+00, -8.8567e+00],\n",
              "        [ 1.4206e+00, -1.0859e+01, -7.5920e-01, -4.2672e+00, -2.7339e+00,\n",
              "         -1.9288e+00,  1.5880e+00, -5.7196e+00, -2.5648e+00, -3.1362e+00],\n",
              "        [ 1.5573e-02, -1.7333e+01,  2.6237e+00, -1.3850e-01, -1.0466e+01,\n",
              "         -2.2983e+00, -6.8948e+00, -4.1622e+00,  9.0108e-01, -4.5197e+00],\n",
              "        [-2.2037e+00,  3.9729e+00,  1.6057e+00, -1.2166e+00, -4.3969e+00,\n",
              "         -2.2764e+00, -3.6915e+00, -6.5639e+00,  1.9487e+00, -4.7506e+00],\n",
              "        [-5.4005e+00,  5.6808e+00,  2.4386e+00, -7.9946e-01, -3.5477e+00,\n",
              "         -3.8229e+00, -3.3233e+00, -2.2950e+00,  1.0586e+00, -3.4518e+00],\n",
              "        [-1.9017e+00, -1.0467e+01, -4.8700e+00, -8.9963e-01, -2.1748e+00,\n",
              "         -5.1849e-01, -7.7665e+00,  6.4241e+00, -9.5256e-02,  4.7723e+00],\n",
              "        [-5.2864e+00, -2.3300e+00, -1.4872e+00,  1.9881e+00, -3.6508e+00,\n",
              "         -2.6660e+00, -7.6590e+00,  5.5117e+00, -9.8398e-01,  2.2738e+00],\n",
              "        [-6.6633e+00,  8.2025e-02, -5.6787e-01,  1.6925e-01, -3.9185e+00,\n",
              "         -1.7382e+00, -4.2012e+00,  5.7193e-01,  8.7022e-01, -2.0975e+00],\n",
              "        [-5.7741e+00, -8.8401e+00, -4.3365e+00, -5.8289e+00,  7.1183e+00,\n",
              "         -3.9983e+00, -2.4444e+00,  3.0227e+00, -9.4862e-02,  3.1832e+00],\n",
              "        [-4.3660e+00, -4.6151e+00,  7.9856e-01, -5.1488e+00,  1.7801e-01,\n",
              "         -1.8861e+00,  6.0924e+00, -7.0862e+00, -1.8730e+00, -3.7394e+00],\n",
              "        [ 3.5793e+00, -1.1531e+01, -5.5699e+00, -7.1060e-02, -9.0709e+00,\n",
              "          3.4962e-01, -1.2507e+01, -2.2489e+00, -5.4846e+00, -4.9755e+00],\n",
              "        [ 4.2421e-03, -1.2830e+01, -3.2013e+00,  2.8983e-01, -4.8683e+00,\n",
              "          3.1827e-01, -8.2482e+00,  7.3052e+00, -3.2879e-01,  2.9530e+00],\n",
              "        [ 6.2906e+00, -1.0719e+01, -1.8179e+00, -2.3068e-01, -7.3036e+00,\n",
              "          1.7163e+00, -2.8047e+00, -9.6687e+00, -2.2523e+00, -8.4477e+00],\n",
              "        [-4.6330e+00, -3.7795e+00,  4.4647e-01,  5.0146e+00, -3.5050e+00,\n",
              "          6.8775e-01, -7.2873e+00, -7.4766e+00,  2.9253e-02, -4.1000e+00],\n",
              "        [-7.8948e-01, -1.0021e+01, -3.1929e-01, -6.1614e+00, -1.5820e+00,\n",
              "          6.4304e-01,  4.5655e+00, -3.8610e+00, -5.6525e+00, -5.2864e+00],\n",
              "        [-2.9837e+00, -3.8635e+00, -2.8141e+00,  1.0168e+00, -5.2409e+00,\n",
              "          2.3121e+00, -7.7221e+00, -7.3850e+00,  4.0806e+00, -2.5883e+00],\n",
              "        [-3.8286e+00, -6.4914e+00, -3.3384e+00, -4.7105e-01, -3.2399e+00,\n",
              "         -1.6377e+00, -8.6573e+00,  7.4363e+00, -6.1785e-01,  2.9275e+00],\n",
              "        [-6.2266e+00,  5.9921e+00,  1.0891e+00, -6.5438e-01, -2.6384e+00,\n",
              "         -3.4244e+00, -3.8106e+00, -1.3285e+00,  7.6437e-01, -2.5532e+00],\n",
              "        [-3.3578e+00, -4.8872e+00,  1.0789e+00,  4.9299e+00, -9.3481e+00,\n",
              "          1.2506e+00, -1.8170e+00, -4.9838e+00, -3.2821e+00, -6.1669e+00],\n",
              "        [-1.5300e-01, -8.4614e+00,  5.1439e+00, -1.5184e+00, -6.7742e+00,\n",
              "         -4.3704e+00, -6.3739e+00, -2.9974e+00, -8.0198e-01, -3.4582e+00],\n",
              "        [-3.6687e+00, -6.3434e+00, -3.9582e+00, -5.7113e+00,  7.5043e+00,\n",
              "         -3.0743e+00, -1.8736e-01, -8.7449e-01, -1.7176e-01,  1.5782e+00],\n",
              "        [-2.1385e+00, -1.2262e+01, -7.2272e+00, -5.4543e+00,  3.0503e+00,\n",
              "         -2.2036e+00, -4.3124e+00,  6.9082e-01,  6.9311e-01,  4.7805e+00],\n",
              "        [-2.4867e+00, -5.0886e+00, -2.8926e+00, -6.7568e+00,  7.6885e+00,\n",
              "         -4.3882e+00,  1.0011e+00, -1.5849e+00, -8.0292e-01,  7.7631e-01],\n",
              "        [-2.5380e+00, -4.7237e+00,  2.5844e+00,  1.5591e+00, -5.6768e+00,\n",
              "         -1.3635e+00, -5.0269e+00, -5.7414e+00,  9.1674e-01, -1.7678e+00],\n",
              "        [-1.6920e+00, -5.4966e+00, -1.1634e+00, -6.3268e+00,  7.0020e-01,\n",
              "         -3.9197e+00,  4.2380e+00, -4.2085e+00, -2.5262e-01, -7.4027e-01],\n",
              "        [-5.3929e+00, -3.6592e+00, -2.6848e+00, -6.0806e+00,  5.6974e+00,\n",
              "         -3.1765e+00, -2.0269e+00,  5.0901e-01, -8.8174e-01,  1.1427e-02],\n",
              "        [-7.0761e+00,  6.7495e+00,  1.0259e+00,  4.0546e-01, -4.0562e+00,\n",
              "         -4.4673e+00, -5.7910e+00, -1.2401e+00,  3.6856e-01, -3.2174e+00],\n",
              "        [-7.8021e-01, -1.3318e+01, -6.9417e+00, -2.9772e+00, -5.4091e-01,\n",
              "         -1.7219e+00, -7.5258e+00,  8.0055e+00, -9.1653e-01,  4.7290e+00],\n",
              "        [-1.6141e+00, -2.1597e+01,  3.0282e+00,  4.5654e+00, -1.3796e+01,\n",
              "         -2.0873e+00, -1.2231e+01, -4.3206e+00, -9.6699e-01, -7.6892e+00],\n",
              "        [-1.7208e+00, -5.6053e+00, -2.6104e-01, -2.5644e+00, -2.8851e+00,\n",
              "          7.7417e-01,  3.3722e+00, -6.5878e+00, -3.2129e+00, -6.2807e+00],\n",
              "        [-3.8518e+00, -4.9264e+00,  8.9881e-01, -7.8173e-01, -7.2707e+00,\n",
              "         -4.2332e+00,  1.3026e+00, -3.6757e+00, -4.1249e+00, -4.7669e+00],\n",
              "        [ 1.1845e+01, -1.6941e+01, -4.4090e+00, -3.3294e+00, -1.2889e+01,\n",
              "          3.3816e+00, -9.0414e+00, -6.2386e+00,  1.3778e+00, -6.1481e+00],\n",
              "        [-8.5734e+00,  5.2465e+00, -8.8709e-01,  1.3109e+00, -4.5219e+00,\n",
              "         -3.7402e+00, -4.3682e+00,  8.2499e-01,  1.9909e-01, -3.4673e-01],\n",
              "        [-6.1784e+00, -4.4186e+00,  3.7770e+00,  1.0791e+00, -5.3542e+00,\n",
              "         -2.6795e+00, -7.5232e+00, -3.7829e-02,  1.9559e+00, -1.5913e+00],\n",
              "        [-6.5007e+00, -2.9546e+00, -1.7541e-01,  2.8569e+00, -8.5502e+00,\n",
              "          3.5362e-01, -9.0545e+00, -2.1429e+00,  3.8750e+00, -1.0250e+00],\n",
              "        [-5.5931e+00, -9.7580e+00, -4.3429e+00, -3.6116e+00,  7.7800e+00,\n",
              "         -1.7984e-01, -1.5883e+00, -3.1745e+00,  1.7443e+00,  2.0328e+00],\n",
              "        [-1.8769e+00, -8.6502e+00, -3.7605e+00, -8.4179e-02, -5.5054e+00,\n",
              "          6.8600e+00, -1.1263e+01, -7.1439e+00,  1.3082e+00, -5.9508e+00],\n",
              "        [-2.8847e+00, -1.0003e+01,  6.0569e-01, -5.6344e+00, -3.5775e+00,\n",
              "         -1.3125e+00,  8.6122e+00, -1.3368e+01, -1.0964e+00, -5.8381e+00],\n",
              "        [-7.2488e+00, -6.7713e+00, -1.0797e+00,  1.7970e+00, -4.9984e+00,\n",
              "         -3.7851e+00, -1.0538e+01,  8.7273e+00, -9.8050e-05,  2.2630e+00],\n",
              "        [-2.8854e+00, -8.9470e+00, -1.1351e+00,  3.6882e+00, -1.0057e+01,\n",
              "          7.2554e-01, -1.2133e+01, -8.1238e+00,  6.2523e+00, -3.1916e+00],\n",
              "        [-1.6163e+00, -1.3885e+01, -6.5916e+00, -4.9443e+00,  4.5673e+00,\n",
              "         -4.3861e+00, -2.7933e+00, -4.0249e-01, -3.4503e-01,  5.6687e+00],\n",
              "        [ 6.7840e+00, -1.8276e+01, -7.8420e+00, -7.7777e+00, -1.3085e+01,\n",
              "          2.2286e+00, -5.5842e+00, -1.4527e+01,  1.2123e+00, -1.0755e+01],\n",
              "        [-7.9150e+00,  7.1992e+00,  1.6725e+00, -4.7145e-01, -6.8281e+00,\n",
              "         -3.4017e+00, -1.3336e+00, -3.7870e+00,  1.3025e+00, -3.1002e+00],\n",
              "        [-6.2362e+00, -6.2983e+00,  9.5147e+00,  3.2674e+00, -1.1452e+01,\n",
              "         -3.7167e+00, -5.5389e+00, -7.1516e+00,  2.5118e+00, -8.6473e+00],\n",
              "        [-3.4137e+00, -7.6353e+00,  1.1019e+00,  9.1405e+00, -1.4591e+01,\n",
              "          4.5564e-02, -8.1796e+00, -1.0713e+00, -1.6223e+00, -5.4326e+00],\n",
              "        [-9.3797e+00, -9.1281e+00, -5.0417e+00, -3.4926e+00,  5.6647e+00,\n",
              "         -4.2423e-01, -4.3834e+00, -1.1419e-01,  1.1197e+00,  1.8516e+00],\n",
              "        [-6.0940e+00, -6.5634e+00, -6.6007e+00, -5.4980e+00, -4.1116e+00,\n",
              "          4.9525e+00, -5.1700e+00, -8.0364e+00,  1.5500e+00, -7.2165e+00],\n",
              "        [-1.5369e+00, -1.5829e+01, -5.7302e-02, -8.5161e+00, -4.6017e+00,\n",
              "         -1.3973e+00,  8.9742e+00, -1.2395e+01, -5.6765e+00, -9.8283e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}
